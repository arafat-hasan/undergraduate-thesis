\chapter[Conclusion]{Conclusion}
\markboth{Chap. 7\ \ \enspace Conclusion}{Chap 7. Conclusion}

\regularsection
\headerregularsection

\begin{sloppypar} % to suppress overfull box
After having carried out this study, we have reached the following conclusions. Every training is 
unique  and  must  be  evaluated  and  tested  in  order  to  obtain  a  good  detecting  and  tracking 
model. YOLOv5 is the fifth version of the  YOLO object  detection model and the  one  that has 
been  used  all  through  this  work  to  detect  vehicles.  The  most  important  thing  when  training 
YOLOV5 is to obtain a wide dataset of vehicles in all the type of positions, point of views, image 
resolution, forms, brands, etc. By this way, the model learns the concept of vehicle in all its forms 
that would appear in real life and therefore it is going to generalize well the concept of vehicle 
and is going to be able to detect vehicles  in new  images  that  have not  been used to train the 
model. It is better to train the network in the first steps with low resolution images $(416 \times 416)$ 
and then picking randomly network resolution values and changing the network configuration 
in order to obtain a model capable of detecting vehicles in images of high and low resolution. 



It  is  preferable  to  train  YOLOV5  with  anchor  boxes  obtained  from  the  dataset  because  the 
prediction accuracy has been increased. An attempt has been made to reduce the training time 
by  using  initial  weights  obtained  from  the  pre-trained  weights  for  the  COCO  and  ImageNet 
dataset, but this has meant a worsening in all areas. We have made some attempts to see if the 
network can be trained with a lower resolution than 416 or with a subdivision value lower than 
16  but  the  network  fails  in  the  training.  Finally,  after  analysing  all  the  trainings  we  have 
concluded  that  with  the  last  training  we  get  the  best  values  according  accuracy,  recall  and 
mAP@0.5.  This  training  has  been  done  with  the  lowest  value  the  training  accepts  for  the 
subdivision parameter and the best data augmentation parameters. 



The  most  important  thing  about  a  vehicle  tracking  system  is  the  capability  the  model  has  to 
detect  vehicles  because  if  it  is  not  able  to  detect  some  vehicles  it  will  fail  to  track  them.  Our 
system is very accurate at detecting vehicles and that is why we have obtained so good results 
in  the  tracking  process.  The  model  that  contains  the  YOLOV5  object  detector  and  the  SORT 
tracker must be adjusted to the area that the camera is recording. For example, a model that 
detects vehicles very well on a highway will not work so well in a camera installed on a street of 
a city because the interest point will have changed and we will have to modify some parameters 
of the model to suit it to the interests of the recorded area. That is what has happened with the 
highway video and the co-driverâ€™s seat video, the model for the first video must be adjusted with 
a lower confidence threshold than for the second one and also, the interest area is different in 
both videos so the adjustment of the frame is different. In short, the model once installed in a 
camera  must  be  configured  at  the  beginning  depending  on  the  background  and  the  interest 
point and once we have obtained the parameters where the accuracy and speed are the best it 
will work alone. 

\end{sloppypar}


\clearpage\phantomsection % to fix wrong hyperref to this section


%=======================================================================
%%% References 

% \clearpage
\phantomsection
\specialsection % put an indent, see preamble
\headerspecialsection

{\hypersetup{urlcolor=ntnu,linkcolor=sophia} % set clickable URL title color to black, not ntnu like in the main document

\bibliographystyle{unsrtnat-mod}  % NATBIB ref style
\bibliography{references}
}

%=======================================================================

\vspace{2.81ex}

\begin{center}
    {\color{sophia} \Huge
    \adforn{21}
    }
\end{center}
